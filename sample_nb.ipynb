{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NamelessOgya/test-cpu-llm/blob/main/sample_nb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5GbZgJ4X4Q4"
      },
      "source": [
        "# 変数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4NXVNCNXvdM"
      },
      "outputs": [],
      "source": [
        "RESULT_DIR   = '/content/drive/MyDrive/tmp'#結果を格納するディレクトリ\n",
        "MOUNT_GDRIVE = True # google driveをマウントするか\n",
        "REPEAT  = 2 #同じプロンプトで何回繰り返し出力するか"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7OmUOSK-Qxa"
      },
      "source": [
        "# 準備"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu88V9iMYRzR"
      },
      "outputs": [],
      "source": [
        "import csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96y2vPwWXWzS"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timezone, timedelta\n",
        "\n",
        "# JST（UTC+9）タイムゾーンを設定\n",
        "jst = timezone(timedelta(hours=9))\n",
        "\n",
        "# 現在のJSTの日時を取得\n",
        "current_time_jst = datetime.now(jst)\n",
        "\n",
        "# 日付と時間を文字列で取得\n",
        "date_str = current_time_jst.strftime(\"%Y%m%d%H%M%S\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "t01dNv_AcWNT",
        "outputId": "4bdabc0c-0d5c-450e-9c0a-04c7346773b4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'20241103201045'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "date_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfvmtaNHLy5v",
        "outputId": "eb35101e-757e-4575-ff9f-d5f6904d206e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "Mounted at /content/drive\n",
            "mkdir: cannot create directory ‘drive/MyDrive/tmp’: File exists\n"
          ]
        }
      ],
      "source": [
        "%cd /content\n",
        "\n",
        "if MOUNT_GDRIVE:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  !mkdir drive/MyDrive/tmp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bSPCjKz17tB5"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpC6m3wO-TPg"
      },
      "source": [
        "## git clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORWR6YWUz-QG",
        "outputId": "90c1ed67-6606-4068-b9f7-93995fbd7b54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'test-cpu-llm'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 101 (delta 38), reused 70 (delta 13), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (101/101), 21.27 KiB | 622.00 KiB/s, done.\n",
            "Resolving deltas: 100% (38/38), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NamelessOgya/test-cpu-llm.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b9MU72d-YQM"
      },
      "source": [
        "# content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gp08AC-A1rGq"
      },
      "outputs": [],
      "source": [
        "# ##クラスデバッグ用の、ダミーのLLMクラス\n",
        "# package_name = \"dummy_llm_cpp\"\n",
        "# repo_id = \"hoge\"\n",
        "# filename = \"huga\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5To_r3GABPWp"
      },
      "outputs": [],
      "source": [
        "package_name = \"llama_cpp\"\n",
        "repo_id = \"mmnga/ELYZA-japanese-Llama-2-7b-fast-instruct-gguf\"\n",
        "filename = \"ELYZA-japanese-Llama-2-7b-fast-instruct-q4_K_M.gguf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "eHhFrK8bhIAp"
      },
      "outputs": [],
      "source": [
        "# package_name = \"bitnet_cpp\"\n",
        "# repo_id = \"HF1BitLLM/Llama3-8B-1.58-100B-tokens\"\n",
        "# filename = \"i2_s\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bqbbLrtz77wF"
      },
      "outputs": [],
      "source": [
        "# package_name = \"ollama\"\n",
        "# repo_id = \"mmnga/ELYZA-japanese-Llama-2-7b-fast-instruct-gguf\"\n",
        "# filename = \"*q8_0.gguf\"\n",
        "\n",
        "# # ollamaには量子化の機能がない"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUf9bSxQBGjd"
      },
      "source": [
        "## install / import package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fBnE4AF-VaR",
        "outputId": "f699eac8-3f45-4b2f-8af9-393fc8af8630"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/test-cpu-llm\n"
          ]
        }
      ],
      "source": [
        "%cd test-cpu-llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtpzC6c6-VSP",
        "outputId": "4698f43c-67bf-4370-b6c2-da7e95827fc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "package: llama_cpp\n",
            "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cpu\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.1.tar.gz (63.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.26.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.1-cp310-cp310-linux_x86_64.whl size=3482754 sha256=6d95647ff17a705ea42be1c00c1dd9ecfea4e65e29a3dd1378de3320debda5d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/b0/a2/f47d952aec7ab061b9e2a345e23a1e1e137beb7891259e3d0c\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.1\n"
          ]
        }
      ],
      "source": [
        "print(f\"package: {package_name}\")\n",
        "\n",
        "!sed -i 's/\\r$//' ./src/{package_name}/install.sh\n",
        "!chmod +x ./src/{package_name}/install.sh\n",
        "!./src/{package_name}/install.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fCnHFtOdA4U3"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(f'./src/{package_name}')\n",
        "sys.path.append(f'./src/common')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w9BQ8UAKD2h4"
      },
      "outputs": [],
      "source": [
        "from llm_module import LLMModule"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBjBJ6suXcyw"
      },
      "source": [
        "# LLMModuleのインスタンス化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zYbEaIBjEYo"
      },
      "source": [
        "※ bitnet.cppにおいてはとても時間かかります。30GB程度のRAMが必要です。ログが標準出力に出力されません"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "a5d085f47ae74059a3468a3c8ec2cf28"
          ]
        },
        "id": "NkGPnHFbEGlG",
        "outputId": "05585241-37b5-48da-a09f-b40ff21bbb32"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:99: UserWarning: \n",
            "Error while fetching `HF_TOKEN` secret value from your vault: 'Requesting secret HF_TOKEN timed out. Secrets can only be fetched when running from the Colab UI.'.\n",
            "You are not authenticated with the Hugging Face Hub in this notebook.\n",
            "If the error persists, please let us know by opening an issue on GitHub (https://github.com/huggingface/huggingface_hub/issues/new).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5d085f47ae74059a3468a3c8ec2cf28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)ese-Llama-2-7b-fast-instruct-q4_K_M.gguf:   0%|          | 0.00/4.16G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "llm = LLMModule(repo_id, filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4HuiSNGXjFU"
      },
      "source": [
        "# 実験開始"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvjRBOUjXqGp"
      },
      "source": [
        "## 実験メニューの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fNNK__7BYYQw"
      },
      "outputs": [],
      "source": [
        "# 記録用csvを作成\n",
        "result_filename = RESULT_DIR + \"/\" + date_str + \".csv\"\n",
        "\n",
        "\n",
        "# ヘッダーを追加\n",
        "with open(result_filename, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "  writer = csv.writer(file)\n",
        "  writer.writerow([\"package_name\", \"repo_id\", \"filename\", \"職種\", \"業種\",\"業務内容\",\"スキル\", \"自己PR\", \"結果\", \"時間\", \"メモリ\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Uty4dAYtXmcY"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/test-cpu-llm/prompt/pattern.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "  pattern = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iAyyeWbtXne4"
      },
      "outputs": [],
      "source": [
        "with open(\"/content/test-cpu-llm/prompt/prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "  content_base = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B0oycdHqtzqv"
      },
      "outputs": [],
      "source": [
        "\n",
        "with open(\"/content/test-cpu-llm/prompt/output_format.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "  output_format = file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qi1yychjVSls",
        "outputId": "2cef9052-98e8-49c6-8dd9-7761b6f8f9ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===============================\n",
            "=== repeat 0 start!! ===\n",
            "===============================\n",
            "infer for 0 sample..\n",
            "infer for 1 sample..\n",
            "infer for 10 sample..\n",
            "infer for 20 sample..\n",
            "infer for 30 sample..\n",
            "infer for 40 sample..\n",
            "===============================\n",
            "=== repeat 1 start!! ===\n",
            "===============================\n",
            "infer for 0 sample..\n",
            "infer for 1 sample..\n",
            "infer for 10 sample..\n",
            "infer for 20 sample..\n",
            "infer for 30 sample..\n",
            "infer for 40 sample..\n"
          ]
        }
      ],
      "source": [
        "for repeat in range(REPEAT):\n",
        "  print( \"===============================\")\n",
        "  print(f\"=== repeat {repeat} start!! ===\")\n",
        "  print( \"===============================\")\n",
        "\n",
        "  for n, i in enumerate(pattern.split(\"\\n\")):\n",
        "    if (n % 10 == 0) | (n == 1):\n",
        "      print(f\"infer for {n} sample..\")\n",
        "\n",
        "    sample = content_base.format(\n",
        "        shokushu = i.split(\",\")[0],\n",
        "        gyoushu  = i.split(\",\")[1],\n",
        "        naiyou   = i.split(\",\")[2],\n",
        "        skill    = i.split(\",\")[3],\n",
        "        self_pr  = i.split(\",\")[4]\n",
        "    )\n",
        "    input = sample + \"出力の際は必ず以下のフォーマットを守ってください。これから列挙するkeyに対して値の要件を満たすようなテキストを出力してください。\\n\" + output_format\n",
        "    r = llm.infer_with_metrics(input)\n",
        "\n",
        "    r[\"package_name\"] = package_name\n",
        "    r[\"repo_id\"]      = repo_id\n",
        "    r[\"filename\"]     = filename\n",
        "\n",
        "    with open(result_filename, mode=\"a\", newline=\"\", encoding=\"utf-8\") as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerow(\n",
        "        [\n",
        "          r[\"package_name\"],\n",
        "          r[\"repo_id\"],\n",
        "          r[\"filename\"],\n",
        "\n",
        "          i.split(\",\")[0],\n",
        "          i.split(\",\")[1],\n",
        "          i.split(\",\")[2],\n",
        "          i.split(\",\")[3],\n",
        "          i.split(\",\")[4],\n",
        "\n",
        "          r[\"result\"],\n",
        "          \"{:.2f}\".format(r[\"time\"]),\n",
        "          \"{:.2f}\".format(r[\"memory\"]),\n",
        "        ]\n",
        "      )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "eu7xvQ9kvnOR",
        "outputId": "739da1b1-2faa-450c-cb3d-789656f3fa4d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'現在転職を考えています。\\nこれから記載する経歴を参考にして、私のための職務経歴書を作成してください。  \\n  \\n職種: 法人営業\\n業種:  金融\\n業務内容: 法人顧客への資産管理提案、商談対応\\nスキル:  営業経験\\n自己PR:  対話力、\\n出力の際は必ず以下のフォーマットを守ってください。これから列挙するkeyに対して値の要件を満たすようなテキストを出力してください。\\nkey; 概要\\nvalue: これまで行ってきた職務の概要を記載してください。\\n\\nkey: 業務内容\\nvalue: これまで行ってきた業務の内容を箇条書きで記載\\n\\nkey: 成果\\nvalue: 業務の結果得られた成果を記載\\n\\nkey: 活かしたスキル\\nvalue: 職務遂行の際に活かしたスキルを記載\\n\\nkey: 自己PR\\nvalue: 自己PRを記載。各項目に関して項目と具体的内容を記載すること'"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KEAw49ykvE2c",
        "outputId": "4dea6dc5-3bca-40df-adb6-aba4021caccb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'time': 18.357044458389282,\n",
              " 'memory': 5.338977813720703,\n",
              " 'result': '{\"status\": \"OK\", \"response\": \"転職相談を受け付けます。現在の職務内容、転職希望理由、希望する業界や職種、希望する転職先の規模、希望する転職の期限などを教えていただけますと、より具体的な提案が可能です。\"}',\n",
              " 'package_name': 'llama_cpp',\n",
              " 'repo_id': 'elyza/Llama-3-ELYZA-JP-8B-GGUF',\n",
              " 'filename': 'Llama-3-ELYZA-JP-8B-q4_k_m.gguf'}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHrSIySvvC12",
        "outputId": "ece7f6d1-d489-43a0-e0f1-1f0e9f9b19e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'time': 2.3332202434539795,\n",
              " 'memory': 5.338726043701172,\n",
              " 'result': '{\"status\": \"準備完了\"}',\n",
              " 'package_name': 'llama_cpp',\n",
              " 'repo_id': 'elyza/Llama-3-ELYZA-JP-8B-GGUF',\n",
              " 'filename': 'Llama-3-ELYZA-JP-8B-q4_k_m.gguf'}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqCQ_GGH_oWt"
      },
      "source": [
        "# develop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5qVuBf3Aoxr"
      },
      "outputs": [],
      "source": [
        "from llama_cpp  import Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "up8dBezUsoeX"
      },
      "outputs": [],
      "source": [
        "sample = '''\n",
        "\n",
        "現在転職を考えています。\n",
        "これから記載する経歴を参考にして、私のための職務経歴書を作成してください。\n",
        "\n",
        "職種: 営業\n",
        "業種: インターネットサービス\n",
        "スキル: ビジネスレベル英語\n",
        "自己PR: 粘り強さ、体力\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7by2S8OSa60p"
      },
      "outputs": [],
      "source": [
        "llm = Llama.from_pretrained(\n",
        "    repo_id=repo_id,\n",
        "    filename=filename,\n",
        "    verbose=False,\n",
        "    n_ctx = 4096\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qp-dc8eQeu9F"
      },
      "outputs": [],
      "source": [
        "sample_format = '''\n",
        "key; 概要\n",
        "value: これまで行ってきた職務の概要を記載してください。\n",
        "\n",
        "key: 業務内容\n",
        "value: これまで行ってきた業務の内容を箇条書きで記載\n",
        "\n",
        "key: 成果\n",
        "value: 業務の結果得られた成果を記載\n",
        "\n",
        "key: 活かしたスキル\n",
        "value: 職務遂行の際に活かしたスキルを記載\n",
        "\n",
        "key: 自己PR\n",
        "value: 自己PRを記載。各項目に関して項目と具体的内容を記載すること\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dky5enWlhBLF"
      },
      "outputs": [],
      "source": [
        "input = sample + \"出力の際は必ず以下のフォーマットを守ってください。これから列挙するkeyに対して値の要件を満たすようなテキストを出力してください。\\n\" + sample_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "2U0h1Di5hmbX",
        "outputId": "a703e26d-e6a4-4d6b-b642-00a74fdb6670"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\n現在転職を考えています。\\nこれから記載する経歴を参考にして、私のための職務経歴書を作成してください。\\n\\n職種: 営業\\n業種: インターネットサービス\\nスキル: ビジネスレベル英語\\n自己PR: 粘り強さ、体力\\n\\n出力の際は必ず以下のフォーマットを守ってください。これから列挙するkeyに対して値の要件を満たすようなテキストを出力してください。\\n\\nkey; 概要\\nvalue: これまで行ってきた職務の概要を記載してください。\\n\\nkey: 業務内容\\nvalue: これまで行ってきた業務の内容を箇条書きで記載\\n\\nkey: 成果\\nvalue: 業務の結果得られた成果を記載\\n\\nkey: 活かしたスキル\\nvalue: 職務遂行の際に活かしたスキルを記載\\n\\nkey: 自己PR\\nvalue: 自己PRを記載。各項目に関して項目と具体的内容を記載すること\\n\\n'"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UKli5WSidDu_"
      },
      "outputs": [],
      "source": [
        "out = llm.create_chat_completion(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"あなたは優秀なキャリアアドバイザーです。転職したいクライアントから相談を受け、クライアントにとって最適な提案を行うことでクライアントを支援します。結果は必ず日本語で出力するルールになっています。出力はjsonフォーマットでお願いします\",\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": input},\n",
        "    ],\n",
        "    response_format={\n",
        "        \"type\": \"json_object\",\n",
        "    },\n",
        "    temperature=0.7,\n",
        "    max_tokens=3000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "mPF0Dgznplgl",
        "outputId": "3cfb7520-90f1-4941-f7f9-ed34a34e6972"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\"概要\": \"インターネットサービス企業で営業として勤務してきた経歴です。粘り強さと体力が私の強みです。\",\"business\": [\"インターネットサービスの営業として、顧客開拓、営業戦略の立案、提案型営業を行いました。\",\"クライアントのニーズに合ったソリューションを提案し、契約を獲得することを目標に、営業活動を展開していました。\",\"新規顧客獲得、既存顧客の深耕、リードの追客を通して、目標の達成を目指してきました。\"],\"achievement\": [\"新規顧客獲得の達成率は30%以上を維持し、既存顧客との関係を深化させることで、リピートビジネスや紹介を獲得することができました。\",\"粘り強く交渉し、困難な案件を成功に導くことができたため、信頼を得ることができました。\",\"結果として、目標の達成はもちろん、顧客との信頼関係を構築することができました。\"],\"skill\": [\"ビジネスレベルの英語を使用して、海外の顧客やパートナーとの交渉やコミュニケーションを取ることができました。\",\"粘り強さと体力を活かして、困難な交渉や営業活動を通して成果を得ることができました。\"],\"自己PR\": [\"私は粘り強い性格と体力で、困難な案件を成功に導くことができます。粘り強く交渉し、顧客のニーズを理解することで、信頼を得ることができます。インターネットサービス業界での経験を活かして、顧客のニーズに合ったソリューションを提案することができます。\"]}'"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "out[\"choices\"][0][\"message\"][\"content\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IxdoHcO9J71"
      },
      "source": [
        "# gitへのpush"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0futSS53GIq",
        "outputId": "4bc51c15-e89a-4871-a0a4-3749718636fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/test-cpu-llm\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "Changes not staged for commit:\n",
            "  (use \"git add <file>...\" to update what will be committed)\n",
            "  (use \"git restore <file>...\" to discard changes in working directory)\n",
            "\t\u001b[31mmodified:   prompt/pattern.txt\u001b[m\n",
            "\t\u001b[31mmodified:   prompt/prompt.txt\u001b[m\n",
            "\t\u001b[31mmodified:   src/llama_cpp/llm_module.py\u001b[m\n",
            "\n",
            "Untracked files:\n",
            "  (use \"git add <file>...\" to include in what will be committed)\n",
            "\t\u001b[31mprompt/output_format.txt\u001b[m\n",
            "\n",
            "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
          ]
        }
      ],
      "source": [
        "%cd /content/test-cpu-llm\n",
        "# !git pull --ff-only\n",
        "!git status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sR7aVb8CIqA4",
        "outputId": "75e2c457-65f2-4694-eb08-566056a32451"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "add 'prompt/pattern.txt'\n",
            "add 'prompt/prompt.txt'\n",
            "add 'src/llama_cpp/llm_module.py'\n",
            "add 'prompt/output_format.txt'\n"
          ]
        }
      ],
      "source": [
        "!git add -n ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zjneq6kl3Wef"
      },
      "outputs": [],
      "source": [
        "!git add --all ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eePhF_Tf4rqz"
      },
      "outputs": [],
      "source": [
        "!git config --global user.email \"hakuginnnohana@gmail.com\"\n",
        "!git config --global user.name \"NamelessOgya\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6hEOPJA3fHY",
        "outputId": "7db4fe5b-1428-4ff2-f537-6cc1dc1e716b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[main 38fb8fa] enhance prompt. implements chat inference\n",
            " 4 files changed, 84 insertions(+), 66 deletions(-)\n",
            " create mode 100644 prompt/output_format.txt\n",
            " rewrite prompt/pattern.txt (95%)\n"
          ]
        }
      ],
      "source": [
        "!git commit -m\"enhance prompt. implements chat inference\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7a3mhld322n",
        "outputId": "1b8869d5-f8e6-4cf1-941f-dbd3cf8a9f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* \u001b[32mmain\u001b[m\n"
          ]
        }
      ],
      "source": [
        "!git branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16DbkyrL87IH"
      },
      "outputs": [],
      "source": [
        "push_url_with_pat = \"https://\" + userdata.get('pat') + \"@github.com/\"+ userdata.get('git_user_name') + \"/test-cpu-llm.git\"\n",
        "!git remote set-url origin {push_url_with_pat}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJAji3rb9Cb-"
      },
      "outputs": [],
      "source": [
        "# !git remote -v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_afT4BL69T-k",
        "outputId": "a784858d-f208-46c3-bc10-3e72039500e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enumerating objects: 16, done.\n",
            "Counting objects:   6% (1/16)\rCounting objects:  12% (2/16)\rCounting objects:  18% (3/16)\rCounting objects:  25% (4/16)\rCounting objects:  31% (5/16)\rCounting objects:  37% (6/16)\rCounting objects:  43% (7/16)\rCounting objects:  50% (8/16)\rCounting objects:  56% (9/16)\rCounting objects:  62% (10/16)\rCounting objects:  68% (11/16)\rCounting objects:  75% (12/16)\rCounting objects:  81% (13/16)\rCounting objects:  87% (14/16)\rCounting objects:  93% (15/16)\rCounting objects: 100% (16/16)\rCounting objects: 100% (16/16), done.\n",
            "Delta compression using up to 8 threads\n",
            "Compressing objects:  11% (1/9)\rCompressing objects:  22% (2/9)\rCompressing objects:  33% (3/9)\rCompressing objects:  44% (4/9)\rCompressing objects:  55% (5/9)\rCompressing objects:  66% (6/9)\rCompressing objects:  77% (7/9)\rCompressing objects:  88% (8/9)\rCompressing objects: 100% (9/9)\rCompressing objects: 100% (9/9), done.\n",
            "Writing objects:  11% (1/9)\rWriting objects:  22% (2/9)\rWriting objects:  33% (3/9)\rWriting objects:  44% (4/9)\rWriting objects:  55% (5/9)\rWriting objects:  66% (6/9)\rWriting objects:  77% (7/9)\rWriting objects:  88% (8/9)\rWriting objects: 100% (9/9)\rWriting objects: 100% (9/9), 2.81 KiB | 2.81 MiB/s, done.\n",
            "Total 9 (delta 4), reused 0 (delta 0), pack-reused 0\n",
            "remote: Resolving deltas:   0% (0/4)\u001b[K\rremote: Resolving deltas:  25% (1/4)\u001b[K\rremote: Resolving deltas:  50% (2/4)\u001b[K\rremote: Resolving deltas:  75% (3/4)\u001b[K\rremote: Resolving deltas: 100% (4/4)\u001b[K\rremote: Resolving deltas: 100% (4/4), completed with 4 local objects.\u001b[K\n",
            "To https://github.com/NamelessOgya/test-cpu-llm.git\n",
            "   4cf6084..38fb8fa  main -> main\n"
          ]
        }
      ],
      "source": [
        "!git push origin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMmC0Kvx9cmP"
      },
      "outputs": [],
      "source": [
        "!git fetch origin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KeQG6tmXu7gI",
        "outputId": "7109eeae-d580-4051-9cd6-287b2098e10f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Updated 1 path from the index\n"
          ]
        }
      ],
      "source": [
        "!git checkout --theirs sample_nb.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YvE8YIR0u_n4"
      },
      "outputs": [],
      "source": [
        "!git add sample_nb.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDZu1_-SvC2P",
        "outputId": "60e03f37-9c8e-4834-a7bb-22f8679a7c5b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rebasing (2/3)\rRebasing (3/3)\r\r\u001b[KSuccessfully rebased and updated refs/heads/main.\n"
          ]
        }
      ],
      "source": [
        "!git rebase --continue"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pqCQ_GGH_oWt"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMEOdMhVdknLZybuajMJcsH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}