# 背景  
CPUで推論可能なLLMをいろいろ試したい。  
  
# 対象  
llama.cpp