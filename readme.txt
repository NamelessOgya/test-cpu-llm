# 背景  
CPUで推論可能なLLMをいろいろ試したい。  
  
# 対象パッケージ  

llama.cpp